{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7157c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -U gensim --user\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3721b3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01100000</td>\n",
       "      <td>structural conservation among variants sars-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001000</td>\n",
       "      <td>effective management idiopathic intracranial h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001000</td>\n",
       "      <td>`` 's whole different atmosphere '' qualitativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01100000</td>\n",
       "      <td>modification spike protein vaccines enveloped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001010</td>\n",
       "      <td>analysis prediction covid-19 outbreak pakistan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0  01100000  structural conservation among variants sars-co...\n",
       "1  00001000  effective management idiopathic intracranial h...\n",
       "2  00001000  `` 's whole different atmosphere '' qualitativ...\n",
       "3  01100000  modification spike protein vaccines enveloped ...\n",
       "4  00001010  analysis prediction covid-19 outbreak pakistan..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/FullLitCovid/train.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "val = pd.read_csv('../data/FullLitCovid/val.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "test = pd.read_csv('../data/FullLitCovid/test.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b80f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5347a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def break_word(text):\n",
    "    text = text.split(\" \")\n",
    "    texted = [ w for w in text if w.isalpha()]\n",
    "    #print(texted)\n",
    "    return texted\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=break_word(r[1]), tags=[r[0]]), axis=1)\n",
    "val_tagged = val.apply(\n",
    "    lambda r: TaggedDocument(words=break_word(r[1]), tags=[r[0]]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=break_word(r[1]), tags=[r[0]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2843c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the CORD19 Dataset\n",
    "eval1 = pd.read_csv('../data/cord19_test.tsv',sep='\\t',header=None,dtype={0:str,1:str})\n",
    "\n",
    "eval_tagged = eval1.apply(\n",
    "    lambda r: TaggedDocument(words=break_word(r[1]), tags=[r[0]]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d91cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ([structural, conservation, among, variants, s...\n",
       "1        ([effective, management, idiopathic, intracran...\n",
       "2        ([whole, different, atmosphere, qualitative, e...\n",
       "3        ([modification, spike, protein, vaccines, enve...\n",
       "4        ([analysis, prediction, outbreak, pakistan, st...\n",
       "                               ...                        \n",
       "24713    ([seroprevalence, healthcare, workers, swiss, ...\n",
       "24714    ([surgical, response, pandemic, singapore, per...\n",
       "24715    ([use, ct, artificial, intelligence, suspected...\n",
       "24716    ([effect, famotidine, hospitalized, patients, ...\n",
       "24717    ([clinical, implications, coronavirus, disease...\n",
       "Length: 24718, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ae6614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ([impacted, immunisation, service, delivery, a...\n",
       "1       ([new, insights, seriousness, acute, myocardia...\n",
       "2       ([guidelines, adaptation, outbreak, management...\n",
       "3       ([implementing, strategies, workplace, level, ...\n",
       "4       ([global, healthcare, resource, efficiency, ma...\n",
       "                              ...                        \n",
       "7058    ([big, seroprevalence, data, pakistan, herd, i...\n",
       "7059    ([effect, prehabilitation, enhanced, recovery,...\n",
       "7060    ([cardiovascular, system, simply, viewer, lead...\n",
       "7061    ([precision, medicine, potential, target, apri...\n",
       "7062    ([comparative, analysis, diagnostic, performan...\n",
       "Length: 7063, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c634cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ([the, influenza, pandemic, in, england, and, ...\n",
       "1     ([buried, treasure, evolutionary, perspectives...\n",
       "2     ([polyether, ionophores, and, promising, biolo...\n",
       "3     ([stillbirth, during, infection, with, middle,...\n",
       "4     ([approved, antiviral, drugs, over, the, past,...\n",
       "                            ...                        \n",
       "95    ([proposed, calfhood, immunization, program, f...\n",
       "96    ([risk, of, bacterial, coinfections, in, febri...\n",
       "97    ([early, days, genomics, and, human, responses...\n",
       "98    ([autophagic, machinery, activated, by, dengue...\n",
       "99    ([development, of, a, multiplex, one, step, th...\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1f069",
   "metadata": {},
   "source": [
    "Distributed Bag of Words (DBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b36a33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24718/24718 [00:00<00:00, 3542621.09it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc9c981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24718/24718 [00:00<00:00, 2423894.28it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1080170.93it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 760279.89it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1549860.32it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1304873.46it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 2006868.10it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1477396.28it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1181048.58it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1378452.70it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1639568.05it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1667011.94it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1810059.99it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 873021.59it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1173309.56it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1476849.09it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1528856.34it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1771250.02it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1653426.57it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1906873.52it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1549860.32it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 2091862.68it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1728489.60it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1651424.94it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1647750.38it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1879154.02it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1494648.61it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1459016.67it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1402166.74it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1191308.42it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1523307.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a49d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, epochs=20)) for doc in sents])\n",
    "    return targets, regressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f0f4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.3645759592241257\n",
      "Testing F1 score: 0.29086556907259203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5, solver='lbfgs', max_iter=500)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9326e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.36409966024915064\n",
      "Testing F1 score: 0.2892470996855133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_val, X_val = vec_for_learning(model_dbow, val_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5, solver='lbfgs', max_iter=500)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_val_pred = logreg.predict(X_val)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_val, y_val_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_val, y_val_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212dbbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.11\n",
      "Testing F1 score: 0.05894736842105264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_eval, X_eval = vec_for_learning(model_dbow, eval_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5, solver='lbfgs', max_iter=500)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_evl_pred = logreg.predict(X_eval)\n",
    "#from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_eval, y_evl_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_eval, y_evl_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f3b4b0",
   "metadata": {},
   "source": [
    "Distributed Memory (DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ed56b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24718/24718 [00:00<00:00, 1679733.09it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d4070c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24718/24718 [00:00<00:00, 2441302.81it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1180887.15it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1400613.42it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1692926.29it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 805691.78it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1653110.20it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1430905.21it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1239906.79it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1221629.47it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1372594.48it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1240040.26it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1434687.27it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1449855.35it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1075397.86it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1651661.72it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1627394.69it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1196740.27it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1078261.12it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1157291.55it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 2253114.41it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1078305.97it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1358084.42it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1181075.49it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1541701.58it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1644092.14it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1127255.40it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1289856.63it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1382717.91it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1207627.33it/s]\n",
      "100%|██████████| 24718/24718 [00:00<00:00, 1305481.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f759700c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5078578507716268\n",
      "Testing F1 score: 0.5333509791502056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fa36bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5234994337485843\n",
      "Testing F1 score: 0.5477758524629028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_val, X_val = vec_for_learning(model_dmm, val_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5, solver='lbfgs', max_iter=500)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_val_pred = logreg.predict(X_val)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_val, y_val_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_val, y_val_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9461de86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.19\n",
      "Testing F1 score: 0.20756536017174312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y_eval, X_eval = vec_for_learning(model_dmm, eval_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5, solver='lbfgs', max_iter=500)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_evl_pred = logreg.predict(X_eval)\n",
    "#from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_eval, y_evl_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_eval, y_evl_pred, average='weighted')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
